{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM experiments for sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import softmax\n",
    "# Import generic wrappers\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Abels english dataset and test permormance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('LLM_examples.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I absolutely loved the new movie; it was fanta...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The customer service was excellent; they were ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is the best product I've ever used; highl...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I’m so happy with my recent purchase; it excee...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The event was incredibly well-organized and en...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence Sentiment\n",
       "0  I absolutely loved the new movie; it was fanta...  Positive\n",
       "1  The customer service was excellent; they were ...  Positive\n",
       "2  This is the best product I've ever used; highl...  Positive\n",
       "3  I’m so happy with my recent purchase; it excee...  Positive\n",
       "4  The event was incredibly well-organized and en...  Positive"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test performance of task specific models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Define the model repo\n",
    "model_name = \"cardiffnlp/twitter-roberta-base-sentiment-latest\" \n",
    "\n",
    "\n",
    "# Download pytorch model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_score(review):\n",
    "  tokens = tokenizer.encode(review, return_tensors='pt')\n",
    "  result = model(tokens)\n",
    "  return int(torch.argmax(result.logits)), softmax(result[0][0].detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[86], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted_sentiment\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSentence\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msentiment_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repositories/llm-experiments/.venv/lib/python3.9/site-packages/pandas/core/series.py:4917\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repositories/llm-experiments/.venv/lib/python3.9/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repositories/llm-experiments/.venv/lib/python3.9/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/Repositories/llm-experiments/.venv/lib/python3.9/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repositories/llm-experiments/.venv/lib/python3.9/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[86], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted_sentiment\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSentence\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43msentiment_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[85], line 3\u001b[0m, in \u001b[0;36msentiment_score\u001b[0;34m(review)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msentiment_score\u001b[39m(review):\n\u001b[1;32m      2\u001b[0m   tokens \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mencode(review, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(torch\u001b[38;5;241m.\u001b[39margmax(result\u001b[38;5;241m.\u001b[39mlogits)), softmax(result[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m~/Repositories/llm-experiments/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repositories/llm-experiments/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Repositories/llm-experiments/.venv/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:1195\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1193\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1195\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1206\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1207\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[0;32m~/Repositories/llm-experiments/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repositories/llm-experiments/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Repositories/llm-experiments/.venv/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:832\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    823\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    825\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    826\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    827\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    830\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    831\u001b[0m )\n\u001b[0;32m--> 832\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    844\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    845\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Repositories/llm-experiments/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repositories/llm-experiments/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Repositories/llm-experiments/.venv/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:521\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    510\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    511\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    512\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    518\u001b[0m         output_attentions,\n\u001b[1;32m    519\u001b[0m     )\n\u001b[1;32m    520\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 521\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/Repositories/llm-experiments/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repositories/llm-experiments/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Repositories/llm-experiments/.venv/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:452\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    449\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    450\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 452\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    457\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m~/Repositories/llm-experiments/.venv/lib/python3.9/site-packages/transformers/pytorch_utils.py:239\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repositories/llm-experiments/.venv/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:464\u001b[0m, in \u001b[0;36mRobertaLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m--> 464\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    465\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m~/Repositories/llm-experiments/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repositories/llm-experiments/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Repositories/llm-experiments/.venv/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:363\u001b[0m, in \u001b[0;36mRobertaIntermediate.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    362\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[0;32m--> 363\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate_act_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/Repositories/llm-experiments/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repositories/llm-experiments/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Repositories/llm-experiments/.venv/lib/python3.9/site-packages/transformers/activations.py:78\u001b[0m, in \u001b[0;36mGELUActivation.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data['Predicted_sentiment'] = data['Sentence'].apply(lambda x: sentiment_score(x[:512]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, array([0.10943202, 0.5057827 , 0.38478523], dtype=float32))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_score('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Predicted_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I absolutely loved the new movie; it was fanta...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The customer service was excellent; they were ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is the best product I've ever used; highl...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I’m so happy with my recent purchase; it excee...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The event was incredibly well-organized and en...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>Watched a few episodes of a show I’m catching ...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>The mail today was mostly bills, just the usual.</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>Went for a walk around the neighborhood, it wa...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>Did a load of laundry this morning, just part ...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>I spent some time browsing online stores but d...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1020 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence Sentiment  \\\n",
       "0     I absolutely loved the new movie; it was fanta...  Positive   \n",
       "1     The customer service was excellent; they were ...  Positive   \n",
       "2     This is the best product I've ever used; highl...  Positive   \n",
       "3     I’m so happy with my recent purchase; it excee...  Positive   \n",
       "4     The event was incredibly well-organized and en...  Positive   \n",
       "...                                                 ...       ...   \n",
       "1015  Watched a few episodes of a show I’m catching ...   Neutral   \n",
       "1016   The mail today was mostly bills, just the usual.   Neutral   \n",
       "1017  Went for a walk around the neighborhood, it wa...   Neutral   \n",
       "1018  Did a load of laundry this morning, just part ...   Neutral   \n",
       "1019  I spent some time browsing online stores but d...   Neutral   \n",
       "\n",
       "      Predicted_sentiment  \n",
       "0                       2  \n",
       "1                       2  \n",
       "2                       2  \n",
       "3                       2  \n",
       "4                       2  \n",
       "...                   ...  \n",
       "1015                    2  \n",
       "1016                    1  \n",
       "1017                    2  \n",
       "1018                    1  \n",
       "1019                    1  \n",
       "\n",
       "[1020 rows x 3 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Predicted_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I absolutely loved the new movie; it was fanta...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The customer service was excellent; they were ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is the best product I've ever used; highl...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I’m so happy with my recent purchase; it excee...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The event was incredibly well-organized and en...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  Sentiment  \\\n",
       "0  I absolutely loved the new movie; it was fanta...          2   \n",
       "1  The customer service was excellent; they were ...          2   \n",
       "2  This is the best product I've ever used; highl...          2   \n",
       "3  I’m so happy with my recent purchase; it excee...          2   \n",
       "4  The event was incredibly well-organized and en...          2   \n",
       "\n",
       "   Predicted_sentiment  \n",
       "0                    2  \n",
       "1                    2  \n",
       "2                    2  \n",
       "3                    2  \n",
       "4                    2  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Sentiment'] = data['Sentiment'].apply(lambda x: 2 if x == 'Positive' else 0 if x == 'Negative' else 1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[335   3   2]\n",
      " [ 19 157 164]\n",
      " [  0   0 340]]\n"
     ]
    }
   ],
   "source": [
    "#chech performance\n",
    "from sklearn import metrics\n",
    "\n",
    "# define confusion matrix\n",
    "confusion_matrix = metrics.confusion_matrix(data['Sentiment'], data['Predicted_sentiment'])\n",
    "\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize confusion matrix with sklearn metrics\n",
    "# define matrix and create labels\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [\"Negative\", \"Neutral\", \"Positive\"])\n",
    "\n",
    "# display matrix\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test performance of much smaller model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/MiniLM-L12-H384-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/CA39WS/Repositories/llm-experiments/.venv/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, array([0.48535722, 0.5146428 ], dtype=float32))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the model repo\n",
    "model_name = \"microsoft/MiniLM-L12-H384-uncased\" \n",
    "\n",
    "\n",
    "# Download pytorch model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def sentiment_score(review):\n",
    "  tokens = tokenizer.encode(review, return_tensors='pt')\n",
    "  result = model(tokens)\n",
    "  return int(torch.argmax(result.logits)), softmax(result[0][0].detach().numpy())\n",
    "\n",
    "sentiment_score('Can you classify the sentiment of the following sentence to Positive, Neural and Negative? Sentence: \"very bad\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
